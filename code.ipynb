{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":120972,"databundleVersionId":14460268,"sourceType":"competition"}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-17T09:12:02.534313Z","iopub.execute_input":"2025-11-17T09:12:02.535131Z","iopub.status.idle":"2025-11-17T09:12:03.536327Z","shell.execute_reply.started":"2025-11-17T09:12:02.535102Z","shell.execute_reply":"2025-11-17T09:12:03.535681Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import sys, os, time, math, re\nfrom pathlib import Path\nfrom collections import Counter, defaultdict\nimport pandas as pd\nimport numpy as np\n\n# Installing whisper and ffmpeg \nprint(\"Installing openai-whisper and ffmpeg (may take ~20-60s)...\")\nos.system(\"pip install --quiet openai-whisper==20240930\")\n# installing ffmpeg to ensure whisper can process audio files\nos.system(\"apt-get install -y -qq ffmpeg >/dev/null 2>&1\")\n\n# imports \nimport soundfile as sf\nimport librosa\nimport torch\nimport whisper\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# Config \nINPUT_DIR = '/kaggle/input/nppe-2-automatic-disfluency-restoration'\nAUDIO_DIR = os.path.join(INPUT_DIR, 'downloaded_audios')\nMODEL_SIZE = \"tiny\"\nMAX_TEST_ASR = None    \nMAX_TRAIN_RETRIEVE = 1000\nVERBOSE = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T12:49:42.983195Z","iopub.execute_input":"2025-12-15T12:49:42.983455Z","iopub.status.idle":"2025-12-15T12:51:17.907074Z","shell.execute_reply.started":"2025-12-15T12:49:42.983428Z","shell.execute_reply":"2025-12-15T12:51:17.906482Z"}},"outputs":[{"name":"stdout","text":"Installing openai-whisper and ffmpeg (may take ~20-60s)...\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 800.5/800.5 kB 11.7 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 363.4/363.4 MB 4.4 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.8/13.8 MB 119.5 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 24.6/24.6 MB 92.4 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 883.7/883.7 kB 43.5 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 664.8/664.8 MB 1.9 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 211.5/211.5 MB 8.9 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.3/56.3 MB 35.5 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 127.9/127.9 MB 14.9 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 207.5/207.5 MB 9.1 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 21.1/21.1 MB 98.1 MB/s eta 0:00:00\n","output_type":"stream"},{"name":"stderr","text":"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# load CSVs and disfluency list\ntrain_csv = os.path.join(INPUT_DIR, 'train.csv')\ntest_csv  = os.path.join(INPUT_DIR, 'test.csv')\ndisf_csv  = os.path.join(INPUT_DIR, 'unique_disfluencies.csv')\n\ntrain_df = pd.read_csv(train_csv) if os.path.exists(train_csv) else pd.DataFrame()\ntest_df  = pd.read_csv(test_csv)\ndisf_df  = pd.read_csv(disf_csv) if os.path.exists(disf_csv) else pd.DataFrame()\ndisf_list = [str(x).strip() for x in (disf_df['disfluency'].astype(str).tolist() if not disf_df.empty else []) if str(x).strip()]\ndisf_set = set(disf_list)\nprint(\"Train rows:\", len(train_df), \"Test rows:\", len(test_df), \"unique disfluencies:\", len(disf_set))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T12:51:37.659019Z","iopub.execute_input":"2025-12-15T12:51:37.659723Z","iopub.status.idle":"2025-12-15T12:51:37.682587Z","shell.execute_reply.started":"2025-12-15T12:51:37.659697Z","shell.execute_reply":"2025-12-15T12:51:37.681853Z"}},"outputs":[{"name":"stdout","text":"Train rows: 900 Test rows: 100 unique disfluencies: 29\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# ensure train.clean_transcript exists\nif not train_df.empty:\n    if 'clean_transcript' not in train_df.columns or train_df['clean_transcript'].isnull().any():\n        if disf_list:\n            import re\n            pattern = r\"\\b(\" + \"|\".join(re.escape(w) for w in disf_list) + r\")\\b\"\n            train_df['clean_transcript'] = train_df['transcript'].astype(str).map(lambda s: re.sub(pattern, \"\", s)).map(lambda s: \" \".join(str(s).split()))\n        else:\n            train_df['clean_transcript'] = train_df['transcript'].astype(str)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T12:51:59.361303Z","iopub.execute_input":"2025-12-15T12:51:59.361589Z","iopub.status.idle":"2025-12-15T12:51:59.379327Z","shell.execute_reply.started":"2025-12-15T12:51:59.361568Z","shell.execute_reply":"2025-12-15T12:51:59.378596Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# build train-aug seq counts and context (evidence)\ndef find_insert_sequences(orig_text, clean_text):\n    o = orig_text.split(); c = clean_text.split()\n    i,j=0,0; inserts=[]\n    while i < len(o):\n        if j < len(c) and o[i] == c[j]:\n            i+=1; j+=1\n        else:\n            seq=[]\n            while i < len(o) and not (j < len(c) and o[i] == c[j]):\n                seq.append(o[i]); i+=1\n            if seq:\n                inserts.append((j, tuple(seq)))\n    return inserts\n\naug_seq_counts = Counter() #count fo disfluencies and what comes before and after it\naug_ctx_counts = defaultdict(Counter)\nif not train_df.empty:\n    for _, r in train_df.iterrows():\n        orig = str(r['transcript']).strip(); clean = str(r['clean_transcript']).strip()\n        if not orig: continue\n        otoks = orig.split(); L = len(otoks)\n        for start, seq in find_insert_sequences(orig, clean):\n            aug_seq_counts[seq] += 1\n            left = otoks[start-1] if start-1 >= 0 else None\n            right_idx = start + len(seq)\n            right = otoks[right_idx] if right_idx < L else None\n            aug_ctx_counts[(left, right)][seq] += 1\nprint(\"Train-derived augmented sequences:\", len(aug_seq_counts))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T12:52:55.009939Z","iopub.execute_input":"2025-12-15T12:52:55.010588Z","iopub.status.idle":"2025-12-15T12:52:55.069313Z","shell.execute_reply.started":"2025-12-15T12:52:55.010563Z","shell.execute_reply":"2025-12-15T12:52:55.068724Z"}},"outputs":[{"name":"stdout","text":"Train-derived augmented sequences: 732\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# quick bigram LM for lm_delta checks \n#computes probability of a token sequence to judge whether insertions improve fluency\nfrom collections import defaultdict as _dd, Counter as _Counter\nbigram_counts = _dd(_Counter); unigram_counts = _Counter()\nif not train_df.empty:\n    for s in train_df['transcript'].astype(str).tolist():\n        toks = ['<s>'] + s.split() + ['</s>']\n        for i in range(len(toks)-1):\n            unigram_counts[toks[i]] += 1\n            bigram_counts[toks[i]][toks[i+1]] += 1\n    unigram_counts['</s>'] += 1\nVocab_size = max(1, len(unigram_counts)); alpha_k = 1.0\ndef bigram_logprob(tokens):\n    toks = ['<s>'] + tokens + ['</s>']; lp=0.0\n    for i in range(len(toks)-1):\n        w1,w2 = toks[i], toks[i+1]\n        c_w1 = unigram_counts.get(w1,0)\n        c_w1_w2 = bigram_counts.get(w1,{}).get(w2,0)\n        prob = (c_w1_w2 + alpha_k) / (c_w1 + alpha_k * Vocab_size)\n        lp += math.log(prob)\n    return lp","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T12:53:07.179404Z","iopub.execute_input":"2025-12-15T12:53:07.180149Z","iopub.status.idle":"2025-12-15T12:53:07.332099Z","shell.execute_reply.started":"2025-12-15T12:53:07.180122Z","shell.execute_reply":"2025-12-15T12:53:07.331359Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# load openai-whisper model\nprint(\"Loading openai/whisper model:\", MODEL_SIZE, \"(may take 20-60s)\")\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nwhisper_model = whisper.load_model(MODEL_SIZE, device=device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T12:53:36.055090Z","iopub.execute_input":"2025-12-15T12:53:36.055749Z","iopub.status.idle":"2025-12-15T12:53:38.060472Z","shell.execute_reply.started":"2025-12-15T12:53:36.055723Z","shell.execute_reply":"2025-12-15T12:53:38.059555Z"}},"outputs":[{"name":"stdout","text":"Loading openai/whisper model: tiny (may take 20-60s)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████████████████████████████████| 72.1M/72.1M [00:00<00:00, 141MiB/s]\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# whisper transcription helper (robust)\n#Transcribes audio\n#Falls back to safer decoding if errors occur\n#ASR can fail on noisy/long audio.\ndef transcribe_whisper(path, language=\"hi\"):\n    try:\n        res = whisper_model.transcribe(path, language=language, fp16=(device==\"cuda\"))\n        return res.get('text','').strip()\n    except Exception:\n        try:\n            res = whisper_model.transcribe(path, language=language, temperature=0.0)\n            return res.get('text','').strip()\n        except Exception:\n            return \"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T12:53:57.409801Z","iopub.execute_input":"2025-12-15T12:53:57.410414Z","iopub.status.idle":"2025-12-15T12:53:57.414799Z","shell.execute_reply.started":"2025-12-15T12:53:57.410388Z","shell.execute_reply":"2025-12-15T12:53:57.414014Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# map test ids -> audio paths robustly\n#Matches test IDs to .wav files using multiple heuristics because Audio filenames may not match IDs exactly.\naudio_files = sorted([p for p in Path(AUDIO_DIR).glob(\"*.wav\")]) if os.path.exists(AUDIO_DIR) else []\naudio_map = {p.stem: str(p) for p in audio_files}\ndef find_audio(sid):\n    s = str(sid)\n    if s in audio_map: return audio_map[s]\n    try:\n        if str(int(s)) in audio_map: return audio_map[str(int(s))]\n    except Exception:\n        pass\n    for k,v in audio_map.items():\n        if s in k:\n            return v\n    return None\n\ntest_id_to_audio = {}\nmissing_audio_ids = []\nfor sid in test_df['id'].astype(str).tolist():\n    p = find_audio(sid)\n    if p:\n        test_id_to_audio[sid] = p\n    else:\n        missing_audio_ids.append(sid)\nprint(\"Mapped test audio:\", len(test_id_to_audio), \"Missing audio ids:\", len(missing_audio_ids))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T12:55:01.633399Z","iopub.execute_input":"2025-12-15T12:55:01.634153Z","iopub.status.idle":"2025-12-15T12:55:01.672436Z","shell.execute_reply.started":"2025-12-15T12:55:01.634130Z","shell.execute_reply":"2025-12-15T12:55:01.671564Z"}},"outputs":[{"name":"stdout","text":"Mapped test audio: 100 Missing audio ids: 0\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# helper functions: edit distance + find insertions\n#Finds tokens ASR says but clean text lacks\n#Edit distance helps verify whether an insertion aligns better with spoken audio\ndef token_edit_distance(a, b):\n    a = a.split() if isinstance(a, str) else list(a)\n    b = b.split() if isinstance(b, str) else list(b)\n    m, n = len(a), len(b)\n    if n == 0: return m\n    prev = list(range(n+1))\n    for i in range(1, m+1):\n        cur = [i] + [0]*n\n        for j in range(1, n+1):\n            cost = 0 if a[i-1] == b[j-1] else 1\n            cur[j] = min(prev[j]+1, cur[j-1]+1, prev[j-1]+cost)\n        prev = cur\n    return prev[n]\n\ndef find_insertions(asr_text, clean_text):\n    a = asr_text.split(); c = clean_text.split()\n    i=j=0; inserts=[]\n    while i < len(a) and j < len(c):\n        if a[i] == c[j]:\n            i+=1; j+=1\n        else:\n            seq=[]; start_j=j\n            while i < len(a) and not (j < len(c) and a[i] == c[j]):\n                seq.append(a[i]); i+=1\n            inserts.append((start_j, tuple(seq)))\n    if i < len(a):\n        inserts.append((len(c), tuple(a[i:])))\n    return inserts\n\n_deva_re = re.compile(r'[\\u0900-\\u097F]')\ndef token_is_deva(tok): return bool(_deva_re.search(tok))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T12:55:32.372916Z","iopub.execute_input":"2025-12-15T12:55:32.373241Z","iopub.status.idle":"2025-12-15T12:55:32.380909Z","shell.execute_reply.started":"2025-12-15T12:55:32.373201Z","shell.execute_reply":"2025-12-15T12:55:32.380367Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# TF-IDF retrieval index (fallback)\n#Builds a retrieval index of training clean transcripts for time when asr evidence is insufficient\ntv = None; tv_fit = None\ntrain_texts = []; train_orig_texts = []\nif not train_df.empty:\n    train_texts = train_df['clean_transcript'].fillna('').astype(str).tolist()\n    train_orig_texts = train_df['transcript'].fillna('').astype(str).tolist()\n    vec_limit = min(MAX_TRAIN_RETRIEVE, len(train_texts)) if MAX_TRAIN_RETRIEVE else len(train_texts)\n    if vec_limit > 0:\n        tv = TfidfVectorizer(analyzer='word', token_pattern=r'(?u)\\b\\w+\\b', max_features=20000)\n        tv_fit = tv.fit_transform(train_texts[:vec_limit])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T12:56:02.174633Z","iopub.execute_input":"2025-12-15T12:56:02.174934Z","iopub.status.idle":"2025-12-15T12:56:02.228645Z","shell.execute_reply.started":"2025-12-15T12:56:02.174912Z","shell.execute_reply":"2025-12-15T12:56:02.228113Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# ASR loop: transcribe up to MAX_TEST_ASR and accept insertions conservatively\n#Transcribe audio\nMAX = MAX_TEST_ASR if (MAX_TEST_ASR is not None) else len(test_id_to_audio)\nitems = list(test_id_to_audio.items())[:MAX]\nprint(\"Will transcribe\", len(items), \"test audios for ASR evidence.\")\nstart_all = time.time()\naccepted_preds = {}\nasr_texts = {}\nfor idx,(sid,path) in enumerate(items,1):\n    asr_text = transcribe_whisper(path, language=\"hi\")\n    asr_texts[sid] = asr_text\n    clean_vals = test_df.loc[test_df['id'].astype(str) == sid, 'transcript'].astype(str).values\n    clean = clean_vals[0] if len(clean_vals) > 0 else \"\"\n    pred = clean\n    if asr_text and clean:    ##Compare ASR vs clean transcript\n        inserts = find_insertions(asr_text, clean) #Find candidate insertions\n        accepted=[]\n        for pos, seq in inserts:\n            if not seq: continue  #accept insertions using rules Because ASR output is noisy, we cannot blindly insert everything it detects.\n            # Rule A: contains known disfluency token\n            if any(tok in disf_set for tok in seq):\n                accepted.append((pos, seq, \"disf\")); continue\n            # Rule B: seen in train and reduces ED to ASR\n            freq = aug_seq_counts.get(seq,0)\n            if freq >= 1:\n                cand = clean.split(); cand2 = cand.copy(); cand2[pos:pos] = list(seq)\n                d_before = token_edit_distance(asr_text, clean)\n                d_after  = token_edit_distance(asr_text, \" \".join(cand2))\n                if d_after <= d_before - 0.5:\n                    accepted.append((pos, seq, \"aug_reduces\")); continue\n            # Rule C: short Devanagari filler\n            if len(seq) <= 2 and all(token_is_deva(t) and len(t) <= 3 for t in seq):\n                accepted.append((pos, seq, \"short_deva\")); continue\n        # apply accepted greedily (priority: disf>aug_reduces>short_deva), keep up to 2\n        if accepted:\n            prio = {\"disf\":3,\"aug_reduces\":2,\"short_deva\":1}\n            accepted = sorted(accepted, key=lambda x:(-prio.get(x[2],0), -aug_seq_counts.get(x[1],0)))\n            toks = clean.split(); shift=0; used=[]\n            for pos, seq, tag in accepted:\n                start = pos + shift; end = start + len(seq) - 1\n                conflict=False\n                for s,e in used:\n                    if not (end < s or start > e):\n                        conflict=True; break\n                if conflict: continue\n                toks[start:start] = list(seq)\n                used.append((start, start+len(seq)-1)); shift += len(seq)\n                if len(used) >= 2: break\n            # postprocess collapse repeats and drop long non-deva tokens\n            final=[]\n            for t in toks:\n                if len(final) >= 3 and t == final[-1] == final[-2]:\n                    continue\n                final.append(t)\n            final = [t for t in final if (token_is_deva(t) or len(t) <= 3)]\n            pred = \" \".join(final)\n        else:\n            pred = clean\n    accepted_preds[sid] = pred\n    if idx % 20 == 0 or idx == len(items):\n        print(f\"ASR processed {idx}/{len(items)} - elapsed {time.time()-start_all:.1f}s\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T12:56:32.598756Z","iopub.execute_input":"2025-12-15T12:56:32.599505Z","iopub.status.idle":"2025-12-15T13:01:06.067937Z","shell.execute_reply.started":"2025-12-15T12:56:32.599478Z","shell.execute_reply":"2025-12-15T13:01:06.067278Z"}},"outputs":[{"name":"stdout","text":"Will transcribe 100 test audios for ASR evidence.\nASR processed 20/100 - elapsed 46.7s\nASR processed 40/100 - elapsed 93.7s\nASR processed 60/100 - elapsed 164.8s\nASR processed 80/100 - elapsed 234.6s\nASR processed 100/100 - elapsed 273.5s\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Fallback retrieval for remaining test ids (TF-IDF)\n#Applies retrieval-based insertion if ASR didn’t help.\nfinal_preds = []\ntest_ids = test_df['id'].astype(str).tolist()\nfor sid in test_ids:\n    if sid in accepted_preds:\n        final_preds.append(accepted_preds[sid]); continue\n    clean_vals = test_df.loc[test_df['id'].astype(str) == sid, 'transcript'].astype(str).values\n    clean = clean_vals[0] if len(clean_vals) > 0 else \"\"\n    pred = clean\n    if tv is not None and tv_fit is not None and clean:\n        q = tv.transform([clean])\n        sims = cosine_similarity(q, tv_fit).ravel()\n        best_idx = sims.argmax()\n        if sims[best_idx] > 0.14:\n            cand_orig = train_orig_texts[best_idx]\n            cand_clean = train_texts[best_idx]\n            ins = find_insert_sequences(cand_orig, cand_clean)\n            toks = clean.split(); applied=False\n            for start, seq in ins:\n                if any(tok in disf_set for tok in seq) or aug_seq_counts.get(seq,0) >= 2:\n                    left = cand_clean.split()[start-1] if start-1 >= 0 and len(cand_clean.split())>0 else None\n                    right_idx = start + len(seq)\n                    right = cand_clean.split()[right_idx] if right_idx < len(cand_clean.split()) else None\n                    for pos_try in range(0, len(toks)+1):\n                        left_ok = (left is None) or (pos_try-1 >= 0 and toks[pos_try-1] == left)\n                        right_ok = (right is None) or (pos_try < len(toks) and toks[pos_try] == right)\n                        if left_ok and right_ok:\n                            toks[pos_try:pos_try] = list(seq); applied=True; break\n                if applied: break\n            if applied:\n                final_tok=[]\n                for t in toks:\n                    if len(final_tok) >= 3 and t == final_tok[-1] == final_tok[-2]:\n                        continue\n                    final_tok.append(t)\n                final_tok = [t for t in final_tok if (token_is_deva(t) or len(t) <= 3)]\n                pred = \" \".join(final_tok)\n    final_preds.append(pred)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T13:01:06.068944Z","iopub.execute_input":"2025-12-15T13:01:06.069266Z","iopub.status.idle":"2025-12-15T13:01:06.077972Z","shell.execute_reply.started":"2025-12-15T13:01:06.069248Z","shell.execute_reply":"2025-12-15T13:01:06.077274Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# write submission\nout_df = pd.DataFrame({'id': test_ids, 'transcript': final_preds})\nout_name = 'submission.csv'\nout_df.to_csv(out_name, index=False, encoding='utf-8')\nprint(\"Wrote submission:\", out_name)\nprint(\"Sample 8 outputs:\")\nfor i in range(min(8, len(out_df))):\n    sid = out_df.loc[i,'id']\n    print(\"----\")\n    print(\"id:\", sid)\n    print(\"CLEAN:\", test_df.loc[test_df['id'].astype(str)==sid, 'transcript'].values[0])\n    print(\"PRED :\", out_df.loc[i,'transcript'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T13:01:06.078723Z","iopub.execute_input":"2025-12-15T13:01:06.078959Z","iopub.status.idle":"2025-12-15T13:01:06.097146Z","shell.execute_reply.started":"2025-12-15T13:01:06.078944Z","shell.execute_reply":"2025-12-15T13:01:06.096574Z"}},"outputs":[{"name":"stdout","text":"Wrote submission: submission.csv\nSample 8 outputs:\n----\nid: 8894265003\nCLEAN: जैसे वो दरी वगेरा बना सकते हैं जैसे घर में जो\nPRED : जैसे वो दरी वगेरा बना सकते हैं जैसे घर में जो\n----\nid: 8951729741\nCLEAN: क्या\nPRED : क्या\n----\nid: 4268956831\nCLEAN: हम आप अपने हूं जो खास दोस्त रहता है उससे लड़ाई की हो\nPRED : हम आप अपने हूं जो खास दोस्त रहता है उससे लड़ाई की हो\n----\nid: 1819728609\nCLEAN: सही बात है जिसमें कुछ मोरल हो\nPRED : सही बात है जिसमें कुछ मोरल हो\n----\nid: 5456358058\nCLEAN: तनकियों अं तनकियों के बारे में बात करना काम और ब्रैक्स काम ओर ब्रेस के बीच ब्लैं बैलेंस बनाते बनाने की बात करना रोज रोज़ाना के गोल\nPRED : तनकियों अं तनकियों के बारे में बात करना काम और ब्रैक्स काम ओर ब्रेस के बीच ब्लैं बैलेंस बनाते बनाने की बात करना रोज रोज़ाना के गोल\n----\nid: 7463846466\nCLEAN: जी जी जी\nPRED : जी जी जी\n----\nid: 1974265135\nCLEAN: अच्छा पोर्स हुँ सही है सही रेट अच्छा पर हैड है अच्छा ओके\nPRED : अच्छा पोर्स हुँ सही है सही रेट अच्छा पर हैड है अच्छा ओके\n----\nid: 2894086166\nCLEAN: तो करा ै कि मेडम आप देखिये आप मेरा घाटा करवा री ै ऐसे नीं ो पाएगा तो म के कि ठीक भइया कोई बात नीं म जा रे ैं तो लड़की बोल री ै कि आप तो कुछ ज्यादा ी कम करा दी तो कां से कम करेगा के तुम शांत रो वो करेगा न नी करेगा तो कोई बात नी म किसी दुशरे शॉप\nPRED : तो करा ै कि मेडम आप देखिये आप मेरा घाटा करवा री ै ऐसे नीं ो पाएगा तो म के कि ठीक भइया कोई बात नीं म जा रे ैं तो लड़की बोल री ै कि आप तो कुछ ज्यादा ी कम करा दी तो कां से कम करेगा के तुम शांत रो वो करेगा न नी करेगा तो कोई बात नी म किसी दुशरे शॉप\n","output_type":"stream"}],"execution_count":14}]}